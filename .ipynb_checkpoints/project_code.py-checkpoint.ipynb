{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"DataSets/Dhoni Image/Dhoni of India poses during the India 2015 I (3).jpg\")\n",
    "image_Rgb = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image_Rgb)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(image_gray,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "image_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(image_gray)\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "for x,y,w,h in faces:\n",
    "    face_image = cv2.rectangle(image,(x,y),(x+w,y+h),(255,25,255),3)\n",
    "    roi_gray = face_image[x:x+w,y:y+h]\n",
    "    eyes_image = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for ex,ey,ew,eh in eyes_image:\n",
    "        eye_image = cv2.rectangle(roi_gray,(ex,ey),(ex+ew,ey+eh),(255,255,255),1)\n",
    "\n",
    "plt.imshow(face_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(eye_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_image_if_2_eyes(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "#     image_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    eye_cascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "    faces = face_cascade.detectMultiScale(image)\n",
    "#     print(\"faces is: \",faces)\n",
    "    for x,y,w,h in faces:\n",
    "#         face_image = cv2.rectangle(image,(x,y),(x+w,y+h),(255,255,255),3)\n",
    "#         roi_gray = image[x:x+w,y:y+h]\n",
    "        roi_color = image[x:x+w,y:y+h]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_color)\n",
    "#         print(\"eyes is : \",eyes)\n",
    "        if len(eyes)>=0:\n",
    "            return roi_color\n",
    "#     return result\n",
    "#         for ex,ey,ew,eh in eyes:\n",
    "#             cv2.cvtColor(roi_color,(ex,ey),(ex+ew,ey+eh),(255,0,0),2)\n",
    "\n",
    "result = get_cropped_image_if_2_eyes(\"DataSets/Dhoni Image/Dhoni of India poses during the India 2015 I (3).jpg\")\n",
    "plt.imshow(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = cv2.imread(\"DataSets/Dhoni Image/Dhoni of India appeals as he stumps Jonathan_yythkg.jpg\",cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result = get_cropped_image_if_2_eyes(\"DataSets/Yuvraj Images/1763x2048 Yuvraj Singh.jpg\")\n",
    "print(new_result)\n",
    "plt.imshow(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"DataSets/Dhoni Image/Indian cricketer Mahendra Singh Dhoni smiles during_yythkg.jpg\",cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(image)\n",
    "# next_result = get_cropped_image_if_2_eyes(\"DataSets/Dhoni Image/Indian cricketer Mahendra Singh Dhoni smiles during_yythkg.jpg\")\n",
    "# plt.imshow(next_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./DataSets/\"\n",
    "path_to_cropped_data = \"./DataSets/cropped/\"\n",
    "import os\n",
    "img_dir = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dir.append(entry.path)\n",
    "img_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists(path_to_cropped_data):\n",
    "    shutil.rmtree(path_to_cropped_data)\n",
    "os.mkdir(path_to_cropped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "cropped_image_dirs =[]\n",
    "celebrity_file_name_dict = {'Dhoni Image':[],'Yuvraj Images':[],'Raina Images':[],'Sachin Images':[],\"Virat Images\":[]}\n",
    "for img_d in img_dir:\n",
    "    count = 1\n",
    "    celebrity_name = img_d.split('/')[-1]\n",
    "    print(celebrity_name)\n",
    "    \n",
    "    for entry in os.scandir(img_d):\n",
    "        roi_color = get_cropped_image_if_2_eyes(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_cropped_data + celebrity_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating Cropped Images in folder: \",cropped_folder)\n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\"+cropped_file_name\n",
    "            cv2.imwrite(cropped_file_path,roi_color)\n",
    "            celebrity_file_name_dict[celebrity_name].append(cropped_file_path)\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "def w2d(img,mode = \"haar\",level = 1):\n",
    "    imArray = img\n",
    "    imArray = cv2.cvtColor(imArray,cv2.COLOR_RGB2GRAY)\n",
    "    imArraya = np.float32(imArray)\n",
    "    imArray=imArray/255\n",
    "    # compute coefficients\n",
    "    coeffs = pywt.wavedec2(imArray,mode,level = level)\n",
    "    \n",
    "    # Process Coefficieints\n",
    "    coeffs_H = list(coeffs)\n",
    "    coeffs_H[0]*=0\n",
    "    \n",
    "    # Reconstruction\n",
    "    imArray_H = pywt.waverec2(coeffs_H,mode)\n",
    "    imArray_H*=255\n",
    "    imArray_H = np.uint8(imArray_H)\n",
    "    return imArray_H\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = cv2.imread(\"DataSets/cropped/Dhoni Image/Dhoni Image18.png\")\n",
    "im_har = w2d(cropped_image,'db1',5)\n",
    "plt.imshow(im_har,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = [],[]\n",
    "class_dict = {}\n",
    "count = 0\n",
    "for celebrity_name in celebrity_file_name_dict.keys():\n",
    "    class_dict[celebrity_name] = count\n",
    "    count+=1\n",
    "    \n",
    "for celebrity_name,training_files in celebrity_file_name_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        scaled_raw_img = cv2.resize(img,(32,32))\n",
    "        img_har = w2d(img,'db1',5)\n",
    "        scaled_img_har = cv2.resize(img_har,(32,32))\n",
    "        combined_img = np.vstack((scaled_raw_img.reshape(32*32*3,1),scaled_img_har.reshape(32*32,1)))\n",
    "        x.append(combined_img)\n",
    "        y.append(class_dict[celebrity_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 4096)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x).reshape(len(x),len(x[0])).astype(float)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15., 11., 12., ..., 12.,  5.,  5.])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6842105263157895"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 42,test_size = 0.25)\n",
    "pipe = Pipeline([('scaler',StandardScaler()),('svc',SVC(kernel = 'rbf',C = 10))])\n",
    "pipe.fit(x_train,y_train)\n",
    "pipe.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75         7\n",
      "           1       0.75      0.60      0.67         5\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.75      1.00      0.86         3\n",
      "           4       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.68        19\n",
      "   macro avg       0.63      0.56      0.55        19\n",
      "weighted avg       0.72      0.68      0.67        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pipe.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm':{\n",
    "        'model':SVC(gamma = \"auto\",probability = True),\n",
    "        'params':{\n",
    "            'svc__C':[1,3,5,7,10,15,20,100,500,1000],\n",
    "            'svc__kernel':['rbf','linear']\n",
    "        }\n",
    "    },\n",
    "    'random_forest':{\n",
    "        'model':RandomForestClassifier(),\n",
    "        'params':{\n",
    "            'randomforestclassifier__n_estimators':[1,5,8,10,15,20]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression':{\n",
    "        'model':LogisticRegression(solver = 'liblinear',multi_class = 'auto'),\n",
    "        'params':{\n",
    "            'logisticregression__C':[1,3,5,8,10,15,20]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.509615</td>\n",
       "      <td>{'svc__C': 3, 'svc__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.475275</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.364011</td>\n",
       "      <td>{'logisticregression__C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.509615   \n",
       "1        random_forest    0.475275   \n",
       "2  logistic_regression    0.364011   \n",
       "\n",
       "                                    best_params  \n",
       "0           {'svc__C': 3, 'svc__kernel': 'rbf'}  \n",
       "1  {'randomforestclassifier__n_estimators': 20}  \n",
       "2                  {'logisticregression__C': 1}  "
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo,np in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(),np['model'])\n",
    "    clf = GridSearchCV(pipe,np['params'],cv = 4, return_train_score = False)\n",
    "    clf.fit(x_train,y_train)\n",
    "    scores.append({\n",
    "        'model':algo,\n",
    "        'best_score':clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "df = pd.DataFrame(scores,columns = ['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(C=3, gamma='auto', probability=True))])"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6842105263157895"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['svm'].score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(n_estimators=20))])"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['random_forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5789473684210527"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['random_forest'].score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5789473684210527"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline(steps = [('standardscaler',StandardScaler()),('randomforestclassifier',RandomForestClassifier(n_estimators = 5))])\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1, solver='liblinear'))])"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['logistic_regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['logistic_regression'].score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 1, 0, 0, 0],\n",
       "       [2, 3, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 3, 0],\n",
       "       [1, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf = best_estimators['svm']\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,best_clf.predict(x_test))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAJRCAYAAABbWY2QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dfbhmZX0f+u9vD0NQXrXKyzDEIYKKxgAKlBSTC00KNgKaJgdii2nSNJPT2hZMlPia1J5YrTExcOlpMpogeREFI8eIHESNBslRBBR0mEEFITLDKEms8qLIMPs+f+wNnYKzZzbsZ629nvX5eK2LvZ/9vPzmdsH+zfe+172qtRYAgCGZ6bsAAIDF0sAAAIOjgQEABkcDAwAMjgYGABgcDQwAMDgaGACgd1W1X1V9oKpuqqqNVfXjCz1/t64KAwBYwLlJLm+t/XxV7Z7k8Qs9uWxkBwD0qar2SXJDkh9pu9iYmEICAPr2I0n+Psn5VfWFqnp3Ve250AuWbQKz9R++tjwLmyL//Ki1fZcw9a66c2PfJQAD8sD9m6vLz+vyd+3uT37qryXZ/hfPutbauiSpqmOSfDbJCa21q6vq3CR3tdbesKP3swYGAJi4+WZl3Q5+vCnJptba1fPffyDJqxd6P1NIAECvWmvfSHJ7VT19/qGfSrJhoddIYABgrGa39V3B9v5Tkr+YvwLpa0l+eaEna2AAgN611q5PcsyuPl8DAwBj1Wb7ruBRswYGABgcCQwAjNWsBAYAoDMSGAAYqWYNDABAdyQwADBW1sAAAHRHAgMAY2UNDABAdzQwAMDgmEICgLFaXjdzXBQJDAAwOBIYABgri3gBALojgQGAsbKRHQBAdyQwADBSbuYIANAhCQwAjJU1MAAA3ZHAAMBYWQMDANAdCQwAjJV7IQEAdEcCAwBjZQ0MAEB3NDAAwOCYQgKAsbKRHQBAdyQwADBWFvECAHRHAgMAY2UNDABAdyQwADBSrbmVAABAZyQwADBWrkICAOiOBAYAxspVSAAA3ZHAAMBYWQMDANAdCQwAjNWsfWAAADqjgQEABkcDswTuuvuevOJ1v5NTX/qrOfVfrc316zf2XdLUOedtr8wl11+c8z/+rr5LmWonn3Riblx/ZW7acFXOedXL+y5nKhnjyTPGi9BmuzuWmAZmCbzlD/4wJ/zTY/LhC9+VD17wzvzIUw7pu6Spc/nFH805Z76m7zKm2szMTM4790055dQz8+wjn58zznhJjjji8L7LmirGePKM8XhMrIGpqmdU1W9W1XlVde7810dM6vP6cs+99+a6G9bn5049OUmycuXK7LP3Xj1XNX2+ePWXcve37+67jKl23LFH55Zbbsutt349W7duzUUXfSinzZ/XLA1jPHnGeJFmZ7s7lthEGpiq+s0k70tSST6X5Jr5ry+sqldP4jP7smnzN/KE/fbN69/0+/n5X3p5fuvNf5Dvfu++vsuCRVt18IG5fdMdD32/afOWrFp1YI8VTR9jPHnGeDwmlcD8SpJjW2tvaa39+fzxliTHzf9sajywbVs2fuXmnPGzL8oH3vPOPO5xe+SP/+yivsuCRauqRzzWWuuhkulljCfPGC+SNTCPMJtk1Q94/KD5n/1AVbW2qq6tqmvf/acXTqi0pXXg/k/KAU9+Un7sWc9Ikpx04vOy4Ss391wVLN7mTVtyyOr/9a/t6oMPypYt3+yxouljjCfPGI/HpDayOzvJJ6rqq0lun3/sh5McluQ/7uhFrbV1SdYlydZ/+NogWuYn/ZMn5sD9n5xb/25TDn3K6nz2uuvz1DU/3HdZsGjXXHt9Djvs0KxZc0g2b/5GTj/9xXnZL7qCYykZ48kzxos04Js5TqSBaa1dXlVPy9yU0cGZW/+yKck1rbXhbvu3A699xb/Pb77xrdn6wNYcsuqg/F+vfUXfJU2dN7zjtTnqx4/Mvk/cNxdfc2HO/70Lctn7Lu+7rKmybdu2nHX263PZR96bFTMzec8F78+GDV/pu6ypYownzxiPRy3XucGhJDBD9s+PWtt3CVPvqjvtCQTsugfu3/zIRTwTdN+n/6yz37V7/MTLlvTPZh8YAGBw3MwRAEZqyKs6JDAAwOBIYABgrAZ8FZIEBgAYHAkMAIzVBHbI7YoEBgAYHA0MADA4ppAAYKws4gUA6I4EBgDGyiJeAIDuSGAAYKysgQEA6I4EBgDGyhoYAIDuSGAAYKysgQEA6I4EBgDGSgIDANAdCQwAjJWrkAAAuiOBAYCxsgYGAKA7GhgAYHBMIQHAWFnECwDQHQkMAIzVgBfxamAAgN5V1W1J7k6yLckDrbVjFnq+BgYAxmr5rYF5fmvtH3blidbAAACDI4EBgLFaXmtgWpIrqqol+aPW2rqFnqyBAQAmrqrWJlm73UPrHtaknNBau6Oq9k/ysaq6qbV25Y7eTwMDAGPVYQIz36zsMFVprd0x/887q+qSJMcl2WEDYw0MANCrqtqzqvZ+8OskJyVZv9BrJDAAMFat9V3Bgw5IcklVJXO9yXtba5cv9AINDADQq9ba15IcuZjXaGAAYKyW11VIi2INDAAwOBIYABgrCQwAQHckMAAwVsvvXki7TAIDAAyOBgYAGBxTSAAwVhbxAgB0RwIDAGO1fG4lsGgSGABgcCQwADBWA14Ds2wbmLc+9w19lzD13pa9+i5h6h3fdwEAU2rZNjAAwIQNOIGxBgYAGBwJDACMlVsJAAB0RwIDACPVZu0DAwDQGQkMAIyVq5AAALojgQGAsXIVEgBAdzQwAMDgmEICgLFyGTUAQHckMAAwVi6jBgDojgQGAMZKAgMA0B0JDACMVXMVEgBAZyQwADBW1sAAAHRHAgMAY2UnXgCA7khgAGCsmjUwAACdkcAAwFhZAwMA0B0NDAAwOKaQAGCkmo3sAAC6I4EBgLGyiBcAoDsSGAAYKxvZAQB0RwIDAGNlDQwAQHckMAAwVvaBAQDojgQGAMbKGhgAgO5IYABgrOwDAwDQHQkMAIyVNTAAAN3RwAAAg2MKCQBGqtnIDgCgOxIYABgri3gBALqjgXmM9j7oifnX73tdfu0Tb83aj/33HPvLJ/dd0lSqH1qZIy59a555xdvzrE+cl1W/8Qt9lzSVTj7pxNy4/srctOGqnPOql/ddzlQyxpNnjBdhtnV3LDFTSI9R2zabT/zOX+Qb62/L7nvukX976e/k1qvW5x++urnv0qZK+/7WfPn038rsd+9L7bYiT7/kzfnOJz+fez//lb5LmxozMzM579w35YU/89Js2rQln/3MZfnwpVdk48av9l3a1DDGk2eMx0MC8xjdc+e38431tyVJ7r/3vvzjzXdk7wOe0G9RU2r2u/clSWq3FandViRtuHO3y9Fxxx6dW265Lbfe+vVs3bo1F130oZx2qkRxKRnjyTPGi9RmuzuWmAZmCe27+kk54FlPyebrb+m7lOk0M5NnfvTtOfKGC3LXp2/IvV/wN6qltOrgA3P7pjse+n7T5i1ZterAHiuaPsZ48ozxeHTewFTVL3f9mV1Y+fgfys/94dn52H/9s9x/z/f6Lmc6zc5mw8mvyBeP/XfZ86jDs8fTf7jviqZKVT3isSblWlLGePKM8SINeA1MHwnMG3f0g6paW1XXVtW119xzc5c1PSYzu63Iz/3h2Vn///xtvnz5tX2XM/W23XVv7v7M+ux74tF9lzJVNm/akkNWr3ro+9UHH5QtW77ZY0XTxxhPnjEej4k0MFX1xR0cX0pywI5e11pb11o7prV2zLF7HTaJ0ibiRW/91fzjzZvzuXf/v32XMrV2e+I+WbHPnkmS2mP37PO8I3PfzRZKL6Vrrr0+hx12aNasOSQrV67M6ae/OB++9Iq+y5oqxnjyjPHitNnW2bHUJnUV0gFJTk7yPx/2eCX5/yb0mb1YfczT8mM/9xP55sav599d9t+SJJ/83ffnlk/e0HNl02XlAU/IoW8/K1kxk6rKty7923znE9KupbRt27acdfbrc9lH3psVMzN5zwXvz4YNrvJaSsZ48ozxeNQk5gar6o+TnN9au+oH/Oy9rbV/tbP3eNNT/rVJywk7edu9fZcw9Y6/85q+SwAG5IH7Nz9yEc8E3f2fT+nsd+3e5126pH+2iSQwrbVfWeBnO21eAAAWYiM7ABgrd6MGAOiOBgYAGBxTSAAwVhO4vLkrEhgAYHAkMAAwVhIYAIDuSGAAYKSGfKNLCQwAMDgSGAAYq2W2BqaqViS5Nsnm1topCz1XAgMALBdnJdm4K0/UwADAWM227o6dqKrVSV6U5N27UroGBgBYDv4gyTlJdukGTRoYABipNts6O6pqbVVdu92x9sE6quqUJHe21q7b1dot4gUAJq61ti7Juh38+IQkp1XVzyTZI8k+VfXnrbUzd/R+EhgAGKtlsgamtfaa1trq1tqaJL+Q5K8Xal4SDQwAMECmkABgrHZpuWy3WmufSvKpnT1PAgMADI4GBgAYHFNIADBSbZndSmAxJDAAwOBIYABgrCQwAADdkcAAwFgtw8uod5UEBgAYHAkMAIyUq5AAADokgQGAsbIGBgCgOxIYABgpa2AAADokgQGAsbIGBgCgOxIYABipJoEBAOiOBgYAGBxTSAAwVqaQAAC6I4EBgJGyiBcAoEMSGAAYKwkMAEB3JDAAMFLWwAAAdEgCAwAjJYEBAOiQBAYARkoCAwDQoWWbwPz2lk/1XcLU++2+C4Al8rz9j+i7hKl31Z0b+y6BSWjVdwWPmgQGABicZZvAAACTZQ0MAECHNDAAwOCYQgKAkWqzFvECAHRGAgMAI2URLwBAhyQwADBSzUZ2AADdkcAAwEhZAwMA0CEJDACMlH1gAAA6JIEBgJFqre8KHj0JDAAwOBIYABgpa2AAADokgQGAkZLAAAB0SAMDAAyOKSQAGCmXUQMAdEgCAwAjZREvAECHJDAAMFKtSWAAADojgQGAkWqzfVfw6ElgAIDBkcAAwEjNWgMDANAdCQwAjJSrkAAAOiSBAYCRshMvAECHJDAAMFLuRg0A0CENDAAwOKaQAGCkLOIFAOiQBAYARsqtBAAAOrTTBKaqjk/y20meMv/8StJaa0+bcG0AwAQN+VYCuzKFdH6Sc5Jcl2TbZMsBANi5XWlg7mqtfXjilQAAnRryRnY7bGCq6sfmv/zrqnpzkg8m+f6DP2+tfXHCtQEA/EALJTDvfNj3z9vu65bkJ5e+HACgK0O+CmmHDUxr7SeSpKqe0lr7u+1/VlVPmXRhAAA7siuXUV+yi48BAAPSWnV2LLUdNjBV9bSqenGSfavqtO2OM5PsseSVDNjJJ52YG9dfmZs2XJVzXvXyvsuZWsZ58ozx5J3ztlfmkusvzvkff1ffpUwt5/E4LJTAPCvJzyfZL8n/sd3xz5L82uRLG4aZmZmcd+6bcsqpZ+bZRz4/Z5zxkhxxxOF9lzV1jPPkGeNuXH7xR3POma/pu4yp5TxenNa6OxZSVXtU1eeq6oaqurGq3riz2nfYwLTWLmmtvSzJi1trL9vu+A+ttU/v7I2r6hlV9VNVtdfDHn/hzl47JMcde3RuueW23Hrr17N169ZcdNGHctqpJ/dd1tQxzpNnjLvxxau/lLu/fXffZUwt5/FgfT/JC1prRyY5KskL5zfS3aFdWQPzb6pq3cOPhV5QVf85yYeS/Kck6+enoh7033bhMwdj1cEH5vZNdzz0/abNW7Jq1YE9VjSdjPPkGWOmgfN4cWZbdXYspM25Z/7blfPHgrnNrmxk9/Htvt4jyc8muX0nr/nVJM9trd1TVWuSfKCq1rTWzs3crQimRtUj/zhtyDsDLVPGefKMMdPAeTxcVbUic7v+H5bkna21qxd6/k4bmNba+x/2AX+W5GM7edmKBzup1tptVXVi5pqYp2SBBqaq1iZZmyS1Yt/MzOy5s/J6t3nTlhyyetVD368++KBs2fLNHiuaTsZ58owx08B5vDhd3gtp+9/x89a11h6a0WmtbUtyVFXtl+SSqvrR1tr6Hb3fo7kb9aGZu7HjQr5RVUdtV9Q9SU5J8qQkz97Ri1pr61prx7TWjhlC85Ik11x7fQ477NCsWXNIVq5cmdNPf3E+fOkVfZc1dYzz5BljpoHzePna/nf8/PEDl6O01r6d5FNJFlwzuyt3o/6f+V/zUDNJvpXk1Tt52S8meeBhBT2Q5Ber6o929plDsm3btpx19utz2UfemxUzM3nPBe/Phg1f6busqWOcJ88Yd+MN73htjvrxI7PvE/fNxddcmPN/74Jc9r7L+y5rajiPh6mqnpxka2vt21X1uCQ/neS/L/iaheYGa24y8ZAkm+cfmm0dTSbutvvBJi2BXfK8/Y/ou4Spd9WdG/suYRQeuH9zp+tEr171Lzv7XftP7/jgQktIfizJBUlWZC4suai19l8Xer8FE5jWWquqS1prz300xQIA7Mz8DaKPXsxrdmUNzOeq6jmPriQAYLlqHR5LbYcJTFXtNr9u5XlJfrWqbklyb+auImqtNU0NANCLhaaQPpfkOUle0lEtAECHdrbB3HK2UANTSdJau6WjWgAAdslCDcyTq+rXd/TD1trvT6AeAKAjXW5kt9QWamBWJNkrU7b1PwAwfAs1MFt2dg02ADBcs30X8BgsdBm15AUAWJYWSmB+qrMqAIDOtQFnFTtMYFpr3+qyEACAXbXTmzkCANNpdsB3HdyVWwkAACwrEhgAGKnZaVwDAwCwXGlgAIDBMYUEACM1lZdRAwAsVxIYABipab2VAADAsiSBAYCRsgYGAKBDEhgAGClrYAAAOiSBAYCRksAAAHRIAgMAI+UqJACADklgAGCkZocbwEhgAIDhkcAAwEjNWgMDANAdDQwAMDimkABgpFrfBTwGEhgAYHAkMAAwUm4lAADQIQkMAIzUbLmMGgCgMxIYABgpVyEBAHRIAgMAI+UqJACADklgAGCkZod7EZIEBgAYHgkMAIzUbIYbwUhgAIDBkcAAwEjZBwYAoEMaGABgcEwhAYP3tuzVdwlT7/i+C2AiXEYNANAhCQwAjJRbCQAAdEgCAwAj5TJqAIAOSWAAYKRchQQA0CEJDACMlKuQAAA6JIEBgJGSwAAAdEgCAwAj1VyFBADQHQkMAIyUNTAAAB3SwAAAg2MKCQBGyhQSAECHJDAAMFKt7wIeAwkMADA4EhgAGKlZG9kBAHRHAgMAI+UqJACADklgAGCkJDAAAB2SwADASNkHBgCgQxIYABgp+8AAAHRIAgMAI+UqJACADmlgAIBeVdUhVfXJqtpYVTdW1Vk7e40pJAAYqWV0GfUDSX6jtfb5qto7yXVV9bHW2oYdvUACAwD0qrW2pbX2+fmv706yMcnBC71GAgMAIzW7nDKYeVW1JsnRSa5e6HkSGABg4qpqbVVdu92x9gc8Z68kf5nk7NbaXQu9nwQGAEaqy8uoW2vrkqzb0c+ramXmmpe/aK19cGfvJ4EBAHpVVZXkj5NsbK39/q68RgMDACPVOjx24oQkL0vygqq6fv74mYVeYAoJAOhVa+2qJIu6M5MGBgBGyq0EAAA6JIEBgJGaXdSkzfIigQEABkcCAwAjtRx34t1VEhgAYHAkMAAwUsPNXyQwAMAAaWCWwMknnZgb11+ZmzZclXNe9fK+y5laxnnyjPFk1Q+tzBGXvjXPvOLtedYnzsuq3/iFvkuaSs7jcdDAPEYzMzM579w35ZRTz8yzj3x+zjjjJTniiMP7LmvqGOfJM8aT176/NV8+/bey4aRXZMPJr8g+Jz4nez7naX2XNVWcx4sz2+Gx1CbWwFTVcVV17PzXz6yqX9/ZfQ2G6Lhjj84tt9yWW2/9erZu3ZqLLvpQTjv15L7LmjrGefKMcTdmv3tfkqR2W5HabUXShrwKYflxHo/HRBqYqvrtJOcl+R9V9eYk70iyV5JXV9XrJvGZfVl18IG5fdMdD32/afOWrFp1YI8VTSfjPHnGuCMzM3nmR9+eI2+4IHd9+obc+4Wv9l3RVHEeL85sWmfHUpvUVUg/n+SoJD+U5BtJVrfW7qqq301ydZI3TehzOzd3B/D/XfM3qiVnnCfPGHdkdjYbTn5FVuyzZ5767ldnj6f/cO778tf7rmpqOI/HY1JTSA+01ra11r6b5JbW2l1J0lr7XhaYCquqtVV1bVVdOzt774RKW1qbN23JIatXPfT96oMPypYt3+yxoulknCfPGHdr21335u7PrM++Jx7ddylTxXm8OK3DY6lNqoG5v6oeP//1cx98sKr2zQINTGttXWvtmNbaMTMze06otKV1zbXX57DDDs2aNYdk5cqVOf30F+fDl17Rd1lTxzhPnjGevN2euE9W7DP337baY/fs87wjc9/Nm3uuaro4j8djUlNIP9la+36StNa2b1hWJvk3E/rMXmzbti1nnf36XPaR92bFzEzec8H7s2HDV/oua+oY58kzxpO38oAn5NC3n5WsmElV5VuX/m2+84lr+y5rqjiPF2cSVwd1pZbr3OBuux+8PAsDlp3P7n9s3yVMvePvvKbvEkbhgfs3d3p/6FeueWlnv2vfdtuFS/pncysBABgpN3MEAOiQBAYARmq4+YsEBgAYIAkMAIzUkK9CksAAAIMjgQGAkWoDXgUjgQEABkcDAwAMjikkABgpi3gBADokgQGAkXIrAQCADklgAGCkhpu/SGAAgAGSwADASFkDAwDQIQkMAIyUfWAAADokgQGAkXIzRwCADklgAGCkrIEBAOiQBAYARsoaGACADmlgAIDBMYUEACNlES8AQIckMAAwUrPNIl4AgM5IYABgpIabv0hgAIABksAAwEjNDjiDkcAAAIMjgQGAkXIrAQCADklgAGCk7MQLANAhCQwAjJSrkAAAOiSBAYCRchUSAECHNDAAwOCYQgKAkXIZNQBAhyQwADBSrVnECwDQGQkMAIyUjewAADokgQGAkRryVUjLtoF53v5H9F3C1Lvqzo19lzD1nMfdOP7Oa/ouYeo5l1lulm0DAwBMllsJAAB0SAIDACPlKiQAgA5JYABgpOzECwDQIQkMAIzUkPeBkcAAAIMjgQGAkbIPDABAhzQwAMDgmEICgJGykR0AQIckMAAwUstpI7uq+pMkpyS5s7X2ozt7vgQGAFgO3pPkhbv6ZAkMAIzUcloD01q7sqrW7OrzJTAAwOBIYABgpLrcyK6q1iZZu91D61pr6x7t+2lgAICJm29WHnXD8nAaGAAYqdlldBXSYlkDAwD0rqouTPKZJE+vqk1V9SsLPV8CAwAjtZzyl9baSxfzfAkMADA4EhgAGKnltA/MYklgAIDBkcAAwEhJYAAAOqSBAQAGxxQSAIxUs5EdAEB3JDAAMFIW8QIAdEgCAwAj1SQwAADdkcAAwEi5CgkAoEMSGAAYKVchAQB0SAIDACNlDQwAQIckMAAwUtbAAAB0SAIDACNlJ14AgA5pYACAwTGFBAAjNesyagCA7khgAGCkLOIduXPe9spccv3FOf/j7+q7lKl28kkn5sb1V+amDVflnFe9vO9ypo7zuBvO48lzLo+DBmYJXH7xR3POma/pu4ypNjMzk/POfVNOOfXMPPvI5+eMM16SI444vO+yporzePKcx91wLu+62dY6O5aaBmYJfPHqL+Xub9/ddxlT7bhjj84tt9yWW2/9erZu3ZqLLvpQTjv15L7LmirO48lzHnfDuTwOnTUwVfWnXX0W02fVwQfm9k13PPT9ps1bsmrVgT1WBIvnPGa5aR3+b6lNZBFvVf3Vwx9K8vyq2i9JWmunTeJzmV5V9YjHhnwXVcbJeQxLZ1JXIa1OsiHJu5O0zDUwxyT5vYVeVFVrk6xNksP3e0ZW7XnwhMpjaDZv2pJDVq966PvVBx+ULVu+2WNFsHjOY5Yb+8A80jFJrkvyuiTfaa19Ksn3Wmt/01r7mx29qLW2rrV2TGvtGM0L27vm2utz2GGHZs2aQ7Jy5cqcfvqL8+FLr+i7LFgU5zEsnYkkMK212SRvr6qL5//5zUl91nLwhne8Nkf9+JHZ94n75uJrLsz5v3dBLnvf5X2XNVW2bduWs85+fS77yHuzYmYm77ng/dmw4St9lzVVnMeT5zzuhnN51w15H5jqYv61ql6U5ITW2mt39TUnrv7p4Y7qQFx158a+S5h6z9v/iL5LGAXn8uQ5l7vxqU0ff+RCqQk6/MnP7ex37Vf//rol/bN1koq01j6S5CNdfBYAsGusgQEA6NDUrksBABY25DUwEhgAYHA0MADA4JhCAoCRmtv1ZJgkMADA4EhgAGCkZi3iBQDojgQGAEZqyHdDl8AAAIMjgQGAkbIGBgCgQxIYABgpa2AAADokgQGAkZqVwAAAdEcCAwAj1VyFBADQHQkMAIyUq5AAADqkgQEABscUEgCMlFsJAAB0SAIDACNlES8AQIckMAAwUm4lAADQIQkMAIyUNTAAAB2SwADASNkHBgCgQxIYABgpa2AAADokgQGAkbIPDABAhyQwADBSzVVIAADd0cAAAINjCgkARsoiXgCADklgAGCkbGQHANAhCQwAjJTLqAEAOiSBAYCRsgYGAKBDGhgAGKnWWmfHzlTVC6vqy1V1c1W9emfP18AAAL2qqhVJ3pnkXyR5ZpKXVtUzF3qNBgYARqp1eOzEcUlubq19rbV2f5L3JXnxQi/QwAAAfTs4ye3bfb9p/rEdWrZXIX1q08er7xoWq6rWttbW9V3HNDPGk2eMu2GcJ88Y79wD92/u7HdtVa1Nsna7h9Zt9//PD6pjweBGArO01u78KTxGxnjyjHE3jPPkGeNlpLW2rrV2zHbH9s3lpiSHbPf96iR3LPR+GhgAoG/XJDm8qg6tqt2T/EKSv1roBct2CgkAGIfW2gNV9R+TfDTJiiR/0lq7caHXaGCWlrnWyTPGk2eMu2GcJ88YD0hr7bIkl+3q82vI2wgDAONkDQwAMDgamCWw2O2PWbyq+pOqurOq1vddy7SqqkOq6pNVtbGqbqyqs/quadpU1R5V9bmqumF+jN/Yd03TqqpWVNUXqurSvmthMjQwj9Gj2f6YR+U9SV7YdxFT7oEkv9FaOyLJ8Ule7lxect9P8oLW2pFJjkrywqo6vueaptVZSTb2XQSTo4F57Ba9/TGL11q7MkAWSywAAAQRSURBVMm3+q5jmrXWtrTWPj//9d2Z+4//gjthsjhtzj3z366cPyxEXGJVtTrJi5K8u+9amBwNzGO36O2PYbmrqjVJjk5ydb+VTJ/5qY3rk9yZ5GOtNWO89P4gyTlJZvsuhMnRwDx2i97+GJazqtoryV8mObu1dlff9Uyb1tq21tpRmdtp9Liq+tG+a5omVXVKkjtba9f1XQuTpYF57Ba9/TEsV1W1MnPNy1+01j7Ydz3TrLX27SSfirVdS+2EJKdV1W2Zm9J/QVX9eb8lMQkamMdu0dsfw3JUVZXkj5NsbK39ft/1TKOqenJV7Tf/9eOS/HSSm/qtarq01l7TWlvdWluTuf8e/3Vr7cyey2ICNDCPUWvtgSQPbn+8MclFO9v+mMWrqguTfCbJ06tqU1X9St81TaETkrwsc39jvX7++Jm+i5oyByX5ZFV9MXN/+flYa81lvvAo2IkXABgcCQwAMDgaGABgcDQwAMDgaGAAgMHRwAAAg6OBgYGqqm3zlzqvr6qLq+rxj+G9Tnzwrr1VddpCd1Wvqv2q6j88is/4L1X1ykdbI8D2NDAwXN9rrR3VWvvRJPcn+T+3/2HNWfS/4621v2qtvWWBp+yXZNENDMBS0sDAdPh0ksOqak1Vbayq/zvJ55McUlUnVdVnqurz80nNXklSVS+sqpuq6qok//LBN6qqX6qqd8x/fUBVXVJVN8wf/yzJW5I8dT79+d35572qqq6pqi9W1Ru3e6/XVdWXq+rjSZ7e2WgAU08DAwNXVbsl+RdJvjT/0NOT/Glr7egk9yZ5fZKfbq09J8m1SX69qvZI8q4kpyb5iSQH7uDtz0vyN621I5M8J8mNSV6d5Jb59OdVVXVSksOTHJfkqCTPraqfrKrnZm4r96Mz1yAdu8R/dGDEduu7AOBRe1xVXT//9aczdx+jVUn+rrX22fnHj0/yzCR/O3ero+yeuVsyPCPJra21rybJ/M3u1v6Az3hBkl9M5u6inOQ7VfWEhz3npPnjC/Pf75W5hmbvJJe01r47/xnuEQYsGQ0MDNf3WmtHbf/AfJNy7/YPZe5+Oy992POOSrJU9xGpJG9urf3Rwz7j7CX8DID/jSkkmG6fTXJCVR2WJFX1+Kp6WubugHxoVT11/nkv3cHrP5Hk38+/dkVV7ZPk7sylKw/6aJJ/u93amoOrav8kVyb52ap6XFXtnbnpKoAloYGBKdZa+/skv5Tkwvk7IH82yTNaa/dlbsroI/OLeP9uB29xVpLnV9WXklyX5FmttX/M3JTU+qr63dbaFUnem+Qz88/7QJK9W2ufT/L+JNcn+cvMTXMBLAl3owYABkcCAwAMjgYGABgcDQwAMDgaGABgcDQwAMDgaGAAgMHRwAAAg6OBAQAG5/8HkNvJqhNPjRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm,annot = True)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54545455, 0.45454545, 0.63636364, 0.72727273, 0.8       ,\n",
       "       0.4       , 0.7       ])"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_val_score(best_clf,x,y,cv = 7)\n",
    "cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\bansidharan\\anaconda3\\lib\\site-packages (1.0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['saved_model.pkl']"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To save the trained model\n",
    "!pip install joblib\n",
    "import joblib\n",
    "joblib.dump(best_clf,'saved_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"class_dictionary.json\",'w') as f:\n",
    "    f.write(json.dumps(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "084e0f5bab5ee8357b311e69644543678406d719c423ac0ab51f2ea66481170e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
